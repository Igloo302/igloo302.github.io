<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>语音 on LeaveIt</title>
    <link>https://example.com/tags/%E8%AF%AD%E9%9F%B3/</link>
    <description>Recent content in 语音 on LeaveIt</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 29 Mar 2020 14:52:20 +0000</lastBuildDate>
    
	<atom:link href="https://example.com/tags/%E8%AF%AD%E9%9F%B3/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>「因为人工，所以智能」——迟迟迟迟到的智能语音产品实习随笔</title>
      <link>https://example.com/2020/%E5%9B%A0%E4%B8%BA%E4%BA%BA%E5%B7%A5%E6%89%80%E4%BB%A5%E6%99%BA%E8%83%BD%E8%BF%9F%E8%BF%9F%E8%BF%9F%E8%BF%9F%E5%88%B0%E7%9A%84%E6%99%BA%E8%83%BD%E8%AF%AD%E9%9F%B3%E4%BA%A7%E5%93%81%E5%AE%9E%E4%B9%A0%E9%9A%8F%E7%AC%94/</link>
      <pubDate>Sun, 29 Mar 2020 14:52:20 +0000</pubDate>
      
      <guid>https://example.com/2020/%E5%9B%A0%E4%B8%BA%E4%BA%BA%E5%B7%A5%E6%89%80%E4%BB%A5%E6%99%BA%E8%83%BD%E8%BF%9F%E8%BF%9F%E8%BF%9F%E8%BF%9F%E5%88%B0%E7%9A%84%E6%99%BA%E8%83%BD%E8%AF%AD%E9%9F%B3%E4%BA%A7%E5%93%81%E5%AE%9E%E4%B9%A0%E9%9A%8F%E7%AC%94/</guid>
      <description>此前供职的实习公司是做车联网的头部公司之一，负责的业务板块是OS的语音产品，也就是常说的车载语音助手。虽然实习的时间并不长，但是因为产品组缺人手，业务又很繁杂（为什么繁杂之后也会谈到），所以业务的参与度并不低。
离职的时候，mentor给我的一个建议是，在一周两周内做好实习的总结，将工作和想法记录一下。虽然嘴上答应得好好的，但这件事情就一直在To-Do List里面躺了一二三四个月。迫于进入新一轮的找实习找工作的压力，赶紧把这件要紧事给补上，开启回忆模式。
这篇实习总结将会从四个方面展开——
 智能语音技术的二三事：作为一个「新兴」又「新颖」的产品领域，这么多智能助手背后是什么技术在支持，它的基本原理是什么，局限性在哪里。 当AI从实验室走向应用端：和监控安防、医学影像不同，智能语音可能是唯一一个因AI而生的应用产品，当它走向应用端，产品和设计如何构造它的形态。 To B, or to C, that is the Question：在一个兼具2B属性和2C属性的平台型公司工作是一种什么体验？甲方爸爸和用户爸爸之间会产生冲突吗？ 如何成为一个独当一面的产品经理：关于产品经理这个职业的点滴思考。  智能语音技术的二三事 和机器对话 人机交互是指人类通过某种界面(Interface)与系统进行互动，让系统根据人的意愿执行任务。就计算机而言，从CLI到GUI上，用户通过打孔纸带、键盘、鼠标以及现在最常用的触摸，不断更新的交互界面和交互方式让机器在有限的时间里完成更为复杂的任务，也创造了不同的情感体验，比如在iPhone主屏幕上无意识地滑动。
但是上述任何的交互界面都没有脱离「系统允许我做什么」这个认知前提，也就是说，交互设计的第一要务是让用户尽快建立一个概念模型，IF 输入A THEN 执行B的A和B都是明确且有限的。
从先人发出第一声呢喃开始，语言作为一个高度抽象的交互方式成为了人与其他动物之间重要的区别，所以可以说：语音交互是一种更加智能的交互方式，这给产品设计带来了挑战和机遇：
 非线性性：在携程App上预定一个酒店，我需要遵循「输入日期和地点-选择酒店-选择房型-点击预订-输入个人信息-付款确认」的流程（当然，系统也会允许我回过头修改部分环节的信息）。**语音交互是非线性的，而不遵循一般的渐进式任务流。**语音交互系统需要适应用户任何开启一个任务的方式，同时引导用户补全信息，甚至在允许用户切出又切回一个任务（跨域）——比如在订酒店的时候要求提高语音的音量。 更多信息：语言中包含语气、语调、音色、语速等属性，不同的人在不同的场合提出不同的命令都会影响这种属性，意味在语音交互中可以识别用户身份（声纹识别）、捕捉用户情绪（情绪识别）等等。 通用接口：如果说WIMP的“视窗”（Window）、“图标”（Icon）、“选单”（Menu）以及“指标”（Pointer）给GUI之上的交互行为制定了一个通用范式，从Windows和macOS，甚至Android、iOS之间的交互逻辑并没有本质区别，迁移和学习不再困难。那语音则可以称得上让用户忘记接口的存在，而专注于目标本身。「播放周杰伦的七里香」，我不在乎是QQ音乐还是网易云音乐，甚至还想说一句「这首歌有什么有趣的评论？」。这一点和语音交互的及时反馈、带给人的真实感等等性质是分不开的，有机会再展开讲我的理解。  语音产品小史 单向输出 语音交互(Speech Interaction)和语音用户界面(Voice User Interfaces)让用户可以通过口语（自然语音）让机器和设备执行特定的任务。最开始语音交互被运用于电话客服中，称为交互式语音应答(Interactive Voice Response, IVR)，在这种技术中，真人被高质量的录音交互式脚本所取代，应答者通过按下电话按钮提供答案，比如10086就使用了IVR。
单向输入 单向输入的语音最常见的应用就是语音输入了，比如输入法的语音转文字、微信自带的语音输入、讯飞语记这类长文本记录App，都可以帮助用户更快地进行文字的输入。
这种语音转文字的技术在还可以细分成语音转写和语音听写，这个定义学术界和工业界会有所不同：
    学术界 工业界（以科大讯飞为例）     语音听写 实时语音识别 实时识别短语音（60s以内），一般解决人机对话问题，如语音输入、语音交互   语音转写 非实时语音识别 识别长段的录音（5小时以内），可以分为实时语音转写和非实时语音转写，一般解决人人对话问题，如演讲、会议     资料来源：语音转写技术入门系列课
 双向语音 当电话按钮被口语回复取代，语音交互的过程变成了双向的，通过关键词识别可以执行严格的会话脚本，完成用户的任务。随着AI技术的发展，语音的可用性大幅度提高，诞生了现在的AI骚扰电话电销机器人。下图来自华为云，在AI的帮助下（并非说关键词识别被彻底抛弃了）可以更准确地获知客户回答中表达的肯定、否定态度推进会话的进行。
语音交互技术流程 看完刚刚的语音交互产品演变，可能会产生一个❓——智能语音似乎一点也不智能。这还要从目前语音技术流程说起：</description>
    </item>
    
    <item>
      <title>小度小芦，一个仿佛有点脑子的蓝牙音响</title>
      <link>https://example.com/2019/%E5%B0%8F%E5%BA%A6%E5%B0%8F%E8%8A%A6%E4%B8%80%E4%B8%AA%E4%BB%BF%E4%BD%9B%E6%9C%89%E7%82%B9%E8%84%91%E5%AD%90%E7%9A%84%E8%93%9D%E7%89%99%E9%9F%B3%E5%93%8D/</link>
      <pubDate>Thu, 29 Aug 2019 14:00:25 +0000</pubDate>
      
      <guid>https://example.com/2019/%E5%B0%8F%E5%BA%A6%E5%B0%8F%E8%8A%A6%E4%B8%80%E4%B8%AA%E4%BB%BF%E4%BD%9B%E6%9C%89%E7%82%B9%E8%84%91%E5%AD%90%E7%9A%84%E8%93%9D%E7%89%99%E9%9F%B3%E5%93%8D/</guid>
      <description>人生最大奖！淘宝试用中得的小度蓝牙音箱，一个简短的开箱评测。</description>
    </item>
    
  </channel>
</rss>